{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesla stock price prediction using Elon Musk Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the same algorithms as the paper (https://ieeexplore.ieee.org/abstract/document/9566242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages that are to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jaych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, f1_score\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data by removing puntuation, whitespace, URL's, and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    # Convert from string to array by using quatation regex\n",
    "    tweetsArray = re.findall(\"'([^']*)'\", row[\"Tweets\"])\n",
    "\n",
    "    preprocessedTweets = []\n",
    "    for tweet in tweetsArray:\n",
    "        # Remove all URL's\n",
    "        replaced = re.sub(r'http\\S+', '', tweet)\n",
    "\n",
    "        # Remove all punctuation\n",
    "        replaced = re.sub(r'[^\\w\\s]', '', replaced)\n",
    "\n",
    "        # Only use tweet if it is not an empty space\n",
    "        if replaced != '':\n",
    "            preprocessedTweets.append(replaced)\n",
    "    df.at[i, \"Tweets\"] = preprocessedTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"Total Likes\" column by summing all likes for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLikes = []\n",
    "for likes in df[\"Likes\"]:\n",
    "    likes = likes.replace(\"[\", '').replace(\"]\", '').replace(\" \", '')\n",
    "    split = likes.split(\",\")\n",
    "    likes = list(map(int, split))\n",
    "    totalLikes.append(sum(likes))\n",
    "\n",
    "# Create new column in dataframe with total likes of tweets for that week\n",
    "df[\"Total Likes\"] = totalLikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"Total Retweets\" column by summing all retweets for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRetweets = []\n",
    "for retweets in df[\"Retweets\"]:\n",
    "    retweets = retweets.replace(\"[\", '').replace(\"]\", '').replace(\" \", '')\n",
    "    split = retweets.split(\",\")\n",
    "    retweets = list(map(int, split))\n",
    "    totalRetweets.append(sum(retweets))\n",
    "\n",
    "# Create new column in dataframe with total retweets of tweets for that week\n",
    "df[\"Total Retweets\"] = totalRetweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"Label\" column by using the price change. The label will be \"1\" if the price value rose or stayed the same, and the label will be \"-1\" if the price value decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1\n",
      "1   -1\n",
      "2    1\n",
      "3   -1\n",
      "4    1\n",
      "Name: Label, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df[\"Label\"] = np.where(df[\"Dif\"] >= 0, 1, -1)\n",
    "\n",
    "print(df[\"Label\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create VADER SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "positive_words='buy bull long support undervalued underpriced cheap upward rising trend moon rocket hold breakout call beat support buying holding high profit'\n",
    "negative_words='sell bear bubble bearish short overvalued overbought overpriced expensive downward falling sold sell low put miss resistance squeeze cover seller '\n",
    "\n",
    "dictOfpos = { i : 4 for i in positive_words.split(\" \") }\n",
    "dictOfneg = { i : -4 for i in negative_words.split(\" \")  }\n",
    "Financial_Lexicon = {**dictOfpos, **dictOfneg}\n",
    "\n",
    "sia.lexicon.update(Financial_Lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sentiment analysis on each tweet and create new \"Scores\" column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      " 0                                     [0.5719, 0.5106]\n",
      "1                                   [-0.2023, -0.3182]\n",
      "2    [-0.659, 0.7096, 0.7184, 0.891, -0.1027, -0.7264]\n",
      "3                                            [-0.0516]\n",
      "4                                     [-0.8555, 0.743]\n",
      "Name: Scores, dtype: object\n",
      "\n",
      "Average scores:\n",
      " 0    0.541250\n",
      "1   -0.260250\n",
      "2    0.138483\n",
      "3   -0.051600\n",
      "4   -0.056250\n",
      "Name: Average Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "averageScores = []\n",
    "for tweets in df[\"Tweets\"]:\n",
    "\n",
    "    compoundScoresCombined = []\n",
    "    for tweet in tweets:\n",
    "        polarity_score = sia.polarity_scores(tweet)\n",
    "\n",
    "        # Ignore the polarity score if it is 0 (neutral)\n",
    "        if polarity_score[\"compound\"] != 0:\n",
    "            compoundScoresCombined.append(polarity_score[\"compound\"])\n",
    "\n",
    "    scores.append(compoundScoresCombined)\n",
    "\n",
    "    # Get the average compound score, set score to 0 if there are no tweets\n",
    "    if compoundScoresCombined:\n",
    "        averageScores.append(statistics.fmean(compoundScoresCombined))\n",
    "    else:\n",
    "        averageScores.append(0)\n",
    "\n",
    "# Create new column in dataframe with array of scores for each tweet\n",
    "df[\"Scores\"] = scores\n",
    "\n",
    "# Create new column in dataframe with average score for each row\n",
    "df[\"Average Score\"] = averageScores\n",
    "\n",
    "print(\"Scores:\\n\", df[\"Scores\"].head())\n",
    "print(\"\\nAverage scores:\\n\", df[\"Average Score\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into 80/20 training/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Total Likes\", \"Total Retweets\", \"Average Score\"]]\n",
    "y = df[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.5246636771300448\n",
      "F-score is: 0.6787878787878787\n",
      "Area Under Curve: 0.48731972127694057\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Price Drop       0.36      0.05      0.09       102\n",
      "  Price Rise       0.54      0.93      0.68       121\n",
      "\n",
      "    accuracy                           0.52       223\n",
      "   macro avg       0.45      0.49      0.38       223\n",
      "weighted avg       0.45      0.52      0.41       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_predict)\n",
    "print(\"Accuracy is:\", score)\n",
    "\n",
    "fscore = f1_score(y_test, y_predict)\n",
    "print(\"F-score is:\", fscore)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n",
    "auc = auc(fpr, tpr)\n",
    "print(\"Area Under Curve:\", auc)\n",
    "\n",
    "classificationReport = classification_report(y_test, y_predict, target_names=['Price Drop', 'Price Rise'])\n",
    "print(\"\\nClassification Report:\\n\", classificationReport)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bd2a5b78ae43f40b972c3a027d87436b7dd5c5039e3df15ed19fd1400a67afc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
